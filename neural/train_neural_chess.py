#!/usr/bin/env python3
"""
Neural Chess Engine Training Script
Trains a neural network to play chess through self-play learning
Now with PGN generation and parallel game execution
"""

import torch
import torch.nn as nn
import torch.optim as optim
from .neural_chess_engine import NeuralChessEngine
import matplotlib.pyplot as plt
import numpy as np
import time
import os
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import chess.pgn
import threading
import datetime
import signal
import sys

def cleanup_on_exit():
    """Cleanup function to be called on exit"""
    print("\nðŸ›‘ Interrupt received. Cleaning up...")
    try:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("âœ… CUDA memory cleared")
    except Exception as e:
        print(f"âš ï¸  CUDA cleanup warning: {e}")
    print("ðŸ”„ Exiting...")
    sys.exit(0)

def plot_training_progress(losses, game_scores, save_path="training_progress.png"):
    """Plot training progress"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Plot loss over time
    ax1.plot(losses)
    ax1.set_title('Training Loss Over Time')
    ax1.set_xlabel('Training Step')
    ax1.set_ylabel('Loss')
    ax1.grid(True)
    
    # Plot game scores over time
    ax2.plot(game_scores)
    ax2.set_title('Game Scores Over Time')
    ax2.set_xlabel('Game Number')
    ax2.set_ylabel('Final Score')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path)
    plt.show()

def display_training_status(game_results, game_scores, start_time, num_games):
    """Display real-time training status"""
    if not game_results:
        return
    
    completed = len(game_results)
    elapsed = time.time() - start_time
    progress = (completed / num_games) * 100
    
    # Clear screen (works on most terminals)
    os.system('cls' if os.name == 'nt' else 'clear')
    
    print("ðŸ§  NEURAL CHESS ENGINE - LIVE TRAINING STATUS")
    print("=" * 60)
    print(f"ðŸ• Started: {datetime.datetime.fromtimestamp(start_time).strftime('%H:%M:%S')}")
    print(f"ðŸ• Current: {datetime.datetime.now().strftime('%H:%M:%S')}")
    print(f"â±ï¸  Elapsed: {elapsed/60:.1f} minutes")
    print()
    
    # Progress bar
    bar_length = 40
    filled = int(bar_length * progress / 100)
    progress_bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    print(f"ðŸ“Š Progress: {progress_bar} {progress:.1f}%")
    print(f"ðŸŽ® Games: {completed}/{num_games}")
    print()
    
    # Recent games
    print("ðŸŽ¯ RECENT GAMES:")
    for i, result in enumerate(game_results[-5:]):  # Show last 5 games
        game_num = result['game_num']
        score = result['final_score']
        moves = result['moves_played']
        result_str = result['result']
        print(f"   Game {game_num}: Score {score:.2f} | Moves {moves} | Result {result_str}")
    
    print()
    
    # Performance metrics
    if game_scores:
        avg_score = sum(game_scores) / len(game_scores)
        best_score = max(game_scores)
        worst_score = min(game_scores)
        print(f"ðŸ“ˆ PERFORMANCE:")
        print(f"   Average Score: {avg_score:.2f}")
        print(f"   Best Score: {best_score:.2f}")
        print(f"   Worst Score: {worst_score:.2f}")
        
        # ETA calculation
        if completed > 0:
            avg_time_per_game = elapsed / completed
            remaining_games = num_games - completed
            eta = remaining_games * avg_time_per_game
            print(f"   â° ETA: {eta/60:.1f} minutes")
    
    print("=" * 60)

def play_single_game(game_params):
    """Play a single game and return results - for parallel execution"""
    game_num, epochs_per_game, learning_rate, model_name, existing_model_path = game_params
    
    # Create engine instance - load existing model if available
    if existing_model_path and os.path.exists(existing_model_path):
        print(f"      ðŸ“š Loading existing model: {existing_model_path}")
        engine = NeuralChessEngine(existing_model_path)
    else:
        print(f"      ðŸ†• Creating fresh neural network")
        engine = NeuralChessEngine()
    
    # Adjust learning rate
    for param_group in engine.optimizer.param_groups:
        param_group['lr'] = learning_rate
    
    print(f"ðŸŽ® Game {game_num} starting...")
    
    # Play the game with progress enabled
    game_result = engine.self_play_game(show_progress=True)
    
    # Generate PGN for this game
    if game_result['move_history']:
        pgn_game = engine.generate_pgn_game(
            game_result['move_history'], 
            game_result['result']
        )
        engine.save_game_to_history(pgn_game, game_num, game_result)
    
    # Train the model on this game's data with progress
    if len(engine.training_positions) > 0:
        engine.train_model_with_progress(epochs_per_game)
    
    # Get final game score
    final_score = game_result['final_evaluation']
    
    # Save model for this game
    os.makedirs("models", exist_ok=True)
    model_path = f"models/{model_name}_game_{game_num}.pth"
    torch.save(engine.model.state_dict(), model_path)
    
    print(f"âœ… Game {game_num} completed - Score: {final_score:.3f}, Moves: {game_result['moves_played']}")
    
    return {
        'game_num': game_num,
        'final_score': final_score,
        'moves_played': game_result['moves_played'],
        'result': game_result['result'],
        'model_path': model_path,
        'loss': getattr(engine, 'last_loss', 0.0) if hasattr(engine, 'last_loss') else 0.0
    }

def train_neural_chess_engine_parallel(
    num_games=100,
    epochs_per_game=3,
    learning_rate=0.001,
    save_interval=10,
    model_name="chess_neural_model",
    num_parallel_games=3,
    existing_model_path=None
):
    """Train the neural chess engine through parallel self-play"""
    
    print("ðŸ§  Neural Chess Engine Training - PARALLEL MODE")
    print("=" * 50)
    print(f"Training for {num_games} games")
    print(f"Parallel games: {num_parallel_games}")
    print(f"Epochs per game: {epochs_per_game}")
    print(f"Learning rate: {learning_rate}")
    print("=" * 50)
    
    # Adjust parallel games if num_games is less than parallel games
    actual_parallel_games = min(num_parallel_games, num_games)
    if actual_parallel_games != num_parallel_games:
        print(f"âš ï¸  Adjusted parallel games from {num_parallel_games} to {actual_parallel_games} (num_games: {num_games})")
    
    # Training tracking
    all_losses = []
    game_scores = []
    game_results = []
    
    start_time = time.time()
    
    # Start real-time status display in a separate thread
    status_thread = threading.Thread(
        target=lambda: status_updater(game_results, game_scores, start_time, num_games),
        daemon=True
    )
    status_thread.start()
    
    try:
        # Process games in batches of parallel games
        for batch_start in range(0, num_games, actual_parallel_games):
            batch_end = min(batch_start + actual_parallel_games, num_games)
            batch_size = batch_end - batch_start
            
            print(f"\nðŸš€ Starting batch {batch_start//actual_parallel_games + 1}: Games {batch_start + 1}-{batch_end}")
            
            # Prepare game parameters for this batch
            game_params = [
                (game_num + 1, epochs_per_game, learning_rate, model_name, existing_model_path)
                for game_num in range(batch_start, batch_end)
            ]
            
            # Execute games in parallel
            print(f"      ðŸš€ Submitting {len(game_params)} games to parallel executor...")
            
            with ProcessPoolExecutor(max_workers=actual_parallel_games) as executor:
                # Submit all games in the batch
                future_to_game = {
                    executor.submit(play_single_game, params): params[0] 
                    for params in game_params
                }
                
                print(f"      â³ Waiting for games to complete...")
                completed_in_batch = 0
                
                # Collect results as they complete with timeout
                for future in as_completed(future_to_game):
                    game_num = future_to_game[future]
                    try:
                        # Add timeout to prevent hanging
                        result = future.result(timeout=300)  # 5 minutes timeout per game
                        game_results.append(result)
                        game_scores.append(result['final_score'])
                        
                        if result['loss'] > 0:
                            all_losses.append(result['loss'])
                        
                        completed_in_batch += 1
                        print(f"      âœ… Game {game_num} completed ({completed_in_batch}/{len(game_params)})")
                        
                        # Show batch progress
                        if completed_in_batch < len(game_params):
                            remaining = len(game_params) - completed_in_batch
                            print(f"      â³ Waiting for {remaining} more game(s)...")
                        
                    except Exception as e:
                        print(f"      âŒ Game {game_num} failed: {e}")
                        # Cancel the future to free up resources
                        future.cancel()
            
            # Progress update with detailed statistics
            completed_games = len(game_results)
            elapsed = time.time() - start_time
            avg_time_per_game = elapsed / completed_games
            remaining_games = num_games - completed_games
            eta = remaining_games * avg_time_per_game
            
            # Create a visual progress bar
            progress_bar_length = 30
            filled_length = int(progress_bar_length * completed_games / num_games)
            progress_bar = "â–ˆ" * filled_length + "â–‘" * (progress_bar_length - filled_length)
            
            print(f"\nðŸ“Š BATCH PROGRESS SUMMARY:")
            print(f"   {progress_bar} {completed_games}/{num_games} ({100 * completed_games / num_games:.1f}%)")
            print(f"   â±ï¸  Elapsed: {elapsed/60:.1f} minutes")
            print(f"   â° Avg time per game: {avg_time_per_game/60:.1f} minutes")
            print(f"   ðŸŽ¯ ETA: {eta/60:.1f} minutes")
            
            # Show performance metrics
            if game_scores:
                avg_score = sum(game_scores) / len(game_scores)
                best_score = max(game_scores)
                print(f"   ðŸ“ˆ Avg score: {avg_score:.2f}")
                print(f"   ðŸ† Best score: {best_score:.2f}")
            
            # Save models periodically
            if completed_games % save_interval == 0:
                print(f"   ðŸ’¾ Saving models after {completed_games} games...")
        
        # Final save
        os.makedirs("models", exist_ok=True)
        final_model_path = f"models/{model_name}_final.pth"
        if game_results:
            # Use the last completed game's model as the final model
            last_game_result = game_results[-1]
            import shutil
            shutil.copy(last_game_result['model_path'], final_model_path)
            print(f"ðŸ’¾ Final model saved: {final_model_path}")
        
        # Training summary
        total_time = time.time() - start_time
        print(f"\nðŸŽ‰ Training completed!")
        print(f"â±ï¸  Total time: {total_time/60:.1f} minutes")
        print(f"ðŸŽ® Games played: {len(game_results)}")
        print(f"ðŸ§  Model saved: {final_model_path}")
        
        # Plot progress if we have data
        if all_losses and game_scores:
            try:
                plot_training_progress(all_losses, game_scores)
            except Exception as e:
                print(f"Could not plot progress: {e}")
        
        return game_results
        
    except Exception as e:
        print(f"\nðŸ’¥ Training failed with error: {e}")
        import traceback
        traceback.print_exc()
        return []
    
    finally:
        # Cleanup CUDA memory
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("ðŸ§¹ CUDA memory cleared")
        except Exception as e:
            print(f"âš ï¸  CUDA cleanup warning: {e}")
        
        # Stop status thread gracefully
        print("ðŸ”„ Stopping status updates...")
        try:
            # Set a flag to stop the status thread
            if 'status_thread' in locals() and status_thread.is_alive():
                status_thread.join(timeout=3)  # Wait up to 3 seconds
                if status_thread.is_alive():
                    print("âš ï¸  Status thread did not stop gracefully")
                else:
                    print("âœ… Status thread stopped gracefully")
        except Exception as e:
            print(f"âš ï¸  Status thread cleanup warning: {e}")
        
        print("ðŸ§¹ Cleanup completed")

def status_updater(game_results, game_scores, start_time, num_games):
    """Update status display every few seconds"""
    try:
        while len(game_results) < num_games:
            time.sleep(5)  # Update every 5 seconds
            display_training_status(game_results, game_scores, start_time, num_games)
    except Exception as e:
        print(f"âš ï¸  Status updater error: {e}")
    finally:
        print("ðŸ”„ Status updates stopped")

def train_neural_chess_engine(
    num_games=100,
    epochs_per_game=3,
    learning_rate=0.001,
    save_interval=10,
    model_name="chess_neural_model"
):
    """Train the neural chess engine through self-play (legacy single-threaded version)"""
    
    print("ðŸ§  Neural Chess Engine Training - SINGLE THREADED")
    print("=" * 40)
    print(f"Training for {num_games} games")
    print(f"Epochs per game: {epochs_per_game}")
    print(f"Learning rate: {learning_rate}")
    print("=" * 40)
    
    # Create engine
    engine = NeuralChessEngine()
    
    # Adjust learning rate
    for param_group in engine.optimizer.param_groups:
        param_group['lr'] = learning_rate
    
    # Training tracking
    all_losses = []
    game_scores = []
    best_score = float('-inf')
    
    start_time = time.time()
    
    for game_num in range(num_games):
        print(f"\nðŸŽ® Game {game_num + 1}/{num_games}")
        print("=" * 40)
        
        # Play a game and collect training data
        print("ðŸŽ¯ Playing game...")
        game_result = engine.self_play_game(show_progress=True)
        
        if game_result['game_data']:
            # Get final game score
            final_score = game_result['final_evaluation']
            game_scores.append(final_score)
            
            print(f"ðŸ“Š Game Summary:")
            print(f"   Length: {game_result['moves_played']} moves")
            print(f"   Final score: {final_score:.2f}")
            print(f"   Result: {game_result['result']}")
            
            # Generate and save PGN for this game
            if game_result['move_history']:
                print("ðŸ“œ Generating PGN...")
                pgn_game = engine.generate_pgn_game(
                    game_result['move_history'], 
                    game_result['result']
                )
                engine.save_game_to_history(pgn_game, game_num + 1, game_result)
            
            # Train the model
            print("ðŸ§  Training model...")
            engine.train_model_with_progress(epochs_per_game)
            
            # Track loss (simplified - using last batch loss)
            if hasattr(engine, 'last_loss'):
                all_losses.append(engine.last_loss)
            
            # Save model periodically
            if (game_num + 1) % save_interval == 0:
                os.makedirs("models", exist_ok=True)
                model_path = f"models/{model_name}_game_{game_num + 1}.pth"
                torch.save(engine.model.state_dict(), model_path)
                print(f"ðŸ’¾ Model saved: {model_path}")
                
                # Save training data
                engine.save_training_data(f"training_data_game_{game_num + 1}.pkl")
        
        # Progress update with visual bar
        elapsed = time.time() - start_time
        avg_time_per_game = elapsed / (game_num + 1)
        remaining_games = num_games - (game_num + 1)
        eta = remaining_games * avg_time_per_game
        
        # Create progress bar
        progress_bar_length = 30
        filled_length = int(progress_bar_length * (game_num + 1) / num_games)
        progress_bar = "â–ˆ" * filled_length + "â–‘" * (progress_bar_length - filled_length)
        
        print(f"\nðŸ“Š OVERALL PROGRESS:")
        print(f"   {progress_bar} {game_num + 1}/{num_games} ({100 * (game_num + 1) / num_games:.1f}%)")
        print(f"   â±ï¸  Elapsed: {elapsed/60:.1f} minutes")
        print(f"   â° ETA: {eta/60:.1f} minutes")
        
        # Show performance so far
        if game_scores:
            avg_score = sum(game_scores) / len(game_scores)
            best_score = max(game_scores)
            print(f"   ðŸ“ˆ Avg score: {avg_score:.2f}")
            print(f"   ðŸ† Best score: {best_score:.2f}")
        
        print("=" * 40)
    
    # Final save
    os.makedirs("models", exist_ok=True)
    final_model_path = f"models/{model_name}_final.pth"
    torch.save(engine.model.state_dict(), final_model_path)
    print(f"\nðŸ’¾ Final model saved: {final_model_path}")
    
    # Training summary
    total_time = time.time() - start_time
    print(f"\nðŸŽ‰ Training completed!")
    print(f"â±ï¸  Total time: {total_time/60:.1f} minutes")
    print(f"ðŸŽ® Games played: {num_games}")
    print(f"ðŸ§  Model saved: {final_model_path}")
    
    # Plot progress if we have data
    if all_losses and game_scores:
        try:
            plot_training_progress(all_losses, game_scores)
        except Exception as e:
            print(f"Could not plot progress: {e}")
    
    return engine

def test_trained_model(model_path, num_test_games=10):
    """Test a trained neural chess model - PURE EVALUATION ONLY, NO LEARNING"""
    print(f"\nðŸ§ª Testing trained model: {model_path}")
    print("=" * 40)
    print("âš ï¸  TESTING MODE: Model weights will NOT be updated during testing")
    print("=" * 40)
    
    # Load trained model
    engine = NeuralChessEngine(model_path)
    
    # Test performance
    wins = 0
    draws = 0
    losses = 0
    
    for game_num in range(num_test_games):
        print(f"\nðŸŽ® Test game {game_num + 1}/{num_test_games}")
        
        engine.reset_board()
        moves_played = 0
        
        while not engine.board.is_game_over() and moves_played < 50:
            # Get best move from neural network
            best_move = engine.get_best_move(4, 2.0, verbose=False)
            
            if best_move:
                engine.make_move(best_move)
                moves_played += 1
                
                # Show position every 10 moves
                if moves_played % 10 == 0:
                    print(f"Move {moves_played}: {best_move}")
                    print(f"Position evaluation: {engine.evaluate_position_neural(engine.board):.2f}")
            else:
                break
        
        # Determine game result
        if engine.board.is_checkmate():
            if engine.board.turn:  # Black's turn = White won
                wins += 1
                print("âœ… White won by checkmate")
            else:
                losses += 1
                print("âŒ Black won by checkmate")
        elif engine.board.is_stalemate():
            draws += 1
            print("ðŸ¤ Draw by stalemate")
        else:
            draws += 1
            print("ðŸ¤ Draw by other means")
    
    # Test results
    print(f"\nðŸ“Š Test Results ({num_test_games} games):")
    print(f"âœ… Wins: {wins}")
    print(f"ðŸ¤ Draws: {draws}")
    print(f"âŒ Losses: {losses}")
    print(f"ðŸ† Win rate: {100 * wins / num_test_games:.1f}%")

def main():
    """Main training and testing function"""
    # Set up signal handlers for graceful cleanup
    signal.signal(signal.SIGINT, lambda sig, frame: cleanup_on_exit())
    signal.signal(signal.SIGTERM, lambda sig, frame: cleanup_on_exit())
    
    print("ðŸ§  Neural Chess Engine - Training and Testing")
    print("=" * 50)
    print("Choose an option:")
    print("1. ðŸš€ Train new model")
    print("2. ðŸ§ª Test existing model (evaluation only)")
    print("3. ðŸ”„ Train and then test")
    
    choice = input("\nEnter your choice (1-3): ").strip()
    
    if choice == "1":
        # Training only
        run_training()
    elif choice == "2":
        # Testing only
        run_testing()
    elif choice == "3":
        # Train then test
        run_training()
        print("\n" + "="*50)
        run_testing()
    else:
        print("Invalid choice. Running training by default.")
        run_training()

def run_training():
    """Run the training process"""
    print("\nðŸš€ TRAINING MODE")
    print("=" * 30)
    
    # Training parameters
    NUM_GAMES = 30  # Start with fewer games for testing
    EPOCHS_PER_GAME = 3
    LEARNING_RATE = 0.001
    NUM_PARALLEL_GAMES = 3  # Run 3 games simultaneously
    
    # Check for existing models and determine version
    models_dir = "models"
    os.makedirs(models_dir, exist_ok=True)
    
    # Find the latest version
    existing_models = [f for f in os.listdir(models_dir) if f.startswith("chess_neural_v") and f.endswith("_final.pth")]
    existing_model_path = None
    
    if existing_models:
        # Extract version numbers and find the latest
        versions = []
        for model in existing_models:
            try:
                version = int(model.split("_v")[1].split("_")[0])
                versions.append(version)
            except:
                continue
        
        if versions:
            latest_version = max(versions)
            next_version = latest_version + 1
            existing_model_path = f"{models_dir}/chess_neural_v{latest_version}_final.pth"
            print(f"ðŸ“š Found existing model: Version {latest_version}")
            print(f"ðŸ“ Model path: {existing_model_path}")
            print(f"ðŸ”„ Will continue training to create: Version {next_version}")
            
            # Ask user if they want to continue from existing model
            continue_choice = input("Continue training from existing model? (y/n, default: y): ").strip().lower()
            if continue_choice in ['', 'y', 'yes']:
                base_model_name = f"chess_neural_v{next_version}"
                print(f"ðŸš€ Continuing training to create {base_model_name}")
                print(f"ðŸ“š Will load existing model: {existing_model_path}")
            else:
                base_model_name = "chess_neural_v1"
                existing_model_path = None
                print(f"ðŸ†• Starting fresh training with {base_model_name}")
        else:
            base_model_name = "chess_neural_v1"
            print(f"ðŸ†• Starting fresh training with {base_model_name}")
    else:
        base_model_name = "chess_neural_v1"
        print(f"ðŸ†• Starting fresh training with {base_model_name}")
    
    # Get number of games from user
    try:
        num_games = int(input(f"Enter number of games to train (default: {NUM_GAMES}): ").strip() or NUM_GAMES)
    except ValueError:
        num_games = NUM_GAMES
        print(f"Invalid input, using default: {NUM_GAMES} games")
    
    print(f"\nðŸš€ Starting unified training for {num_games} games...")
    print(f"Running {NUM_PARALLEL_GAMES} games simultaneously")
    print(f"ðŸ“š Model version: {base_model_name}")
    
    try:
        game_results = train_neural_chess_engine_parallel(
            num_games=num_games,
            epochs_per_game=EPOCHS_PER_GAME,
            learning_rate=LEARNING_RATE,
            save_interval=10,
            model_name=base_model_name,
            num_parallel_games=NUM_PARALLEL_GAMES,
            existing_model_path=existing_model_path
        )
        
        print("\nðŸŽ‰ Training completed!")
        print("ðŸ“œ All games have been saved to 'games/game_histories.pgn'")
        print(f"ðŸ§  New model version saved: {base_model_name}_final.pth")
        
    except Exception as e:
        print(f"\nðŸ’¥ Training failed: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Final cleanup
        print("\nðŸ§¹ Final cleanup...")
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("âœ… CUDA memory cleared")
        except Exception as e:
            print(f"âš ï¸  CUDA cleanup warning: {e}")
        
        print("ðŸ”„ Returning to main menu...")
        time.sleep(2)  # Give user time to see cleanup messages

def run_testing():
    """Run the testing process"""
    print("\nðŸ§ª TESTING MODE")
    print("=" * 30)
    
    # Check for available models
    models_dir = "models"
    if not os.path.exists(models_dir):
        print("âŒ No models directory found. Please train a model first.")
        return
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
    if not model_files:
        print("âŒ No model files found. Please train a model first.")
        return
    
    print("Available models:")
    for i, model in enumerate(sorted(model_files)):
        print(f"  {i+1}. {model}")
    
    try:
        choice = int(input(f"\nSelect model to test (1-{len(model_files)}): ").strip())
        if 1 <= choice <= len(model_files):
            selected_model = sorted(model_files)[choice-1]
            model_path = f"{models_dir}/{selected_model}"
            
            num_test_games = int(input("Enter number of test games (default: 5): ").strip() or "5")
            
            print(f"\nðŸ§ª Testing model: {selected_model}")
            test_trained_model(model_path, num_test_games)
        else:
            print("Invalid choice.")
    except (ValueError, IndexError):
        print("Invalid input. Please try again.")

if __name__ == "__main__":
    main()
